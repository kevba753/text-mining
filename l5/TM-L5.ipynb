{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L5: Information extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information extraction (IE) is the task of identifying named entities and semantic relations between these entities in text data. In this lab we will focus on two sub-tasks in IE, **named entity recognition** (identifying mentions of entities) and **entity linking** (matching these mentions to entities in a knowledge base)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder about our [Rules for hand-in assignments](https://www.ida.liu.se/~TDDE16/exam.en.shtml#handins) and the [Policy on cheating and plagiarism](https://www.ida.liu.se/~TDDE16/exam.en.shtml#cheating)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we will be using has been tokenized following the conventions of the [Penn Treebank](ftp://ftp.cis.upenn.edu/pub/treebank/public_html/tokenization.html), and we need to prevent spaCy from using its own tokenizer on top of this. We therefore override spaCy&rsquo;s tokenizer with one that simply splits on space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "\n",
    "class WhitespaceTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, text):\n",
    "        return Doc(self.vocab, words=text.split(' '))\n",
    "\n",
    "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main data set for this lab is a collection of news wire articles in which mentions of named entities have been annotated with page names from the [English Wikipedia](https://en.wikipedia.org/wiki/). The next code cell loads the training and the development parts of the data into Pandas data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "with bz2.open('ner-train.tsv.bz2', 'rt') as source:\n",
    "    df_train = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)\n",
    "\n",
    "with bz2.open('ner-dev.tsv.bz2', 'rt') as source:\n",
    "    df_dev = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in these two data frames corresponds to one mention of a named entity and has five columns:\n",
    "\n",
    "1. a unique identifier for the sentence containing the entity mention\n",
    "2. the pre-tokenized sentence, with tokens separated by spaces\n",
    "3. the start position of the token span containing the entity mention\n",
    "4. the end position of the token span (exclusive, as in Python list indexing)\n",
    "5. the entity label; either a Wikipedia page name or the generic label `--NME--`\n",
    "\n",
    "The following cell prints the first five samples from the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000-000</td>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000-000</td>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000-000</td>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>United_Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000-001</td>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000-002</td>\n",
       "      <td>BRUSSELS 1996-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brussels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                          sentence  beg  end  \\\n",
       "0    0000-000  EU rejects German call to boycott British lamb .    0    1   \n",
       "1    0000-000  EU rejects German call to boycott British lamb .    2    3   \n",
       "2    0000-000  EU rejects German call to boycott British lamb .    6    7   \n",
       "3    0000-001                                   Peter Blackburn    0    2   \n",
       "4    0000-002                               BRUSSELS 1996-08-22    0    1   \n",
       "\n",
       "            label  \n",
       "0         --NME--  \n",
       "1         Germany  \n",
       "2  United_Kingdom  \n",
       "3         --NME--  \n",
       "4        Brussels  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this sample, we see that the first sentence is annotated with three entity mentions:\n",
    "\n",
    "* the span 0–1 &lsquo;EU&rsquo; is annotated as a mention but only labelled with the generic `--NME--`\n",
    "* the span 2–3 &lsquo;German&rsquo; is annotated with the page [Germany](http://en.wikipedia.org/wiki/Germany)\n",
    "* the span 6–7 &lsquo;British&rsquo; is annotated with the page [United_Kingdom](http://en.wikipedia.org/wiki/United_Kingdom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Evaluation measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To warm up, we ask you to write code to print the three measures that you will be using for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_report(gold, pred):\n",
    "    \"\"\"Print precision, recall, and F1 score.\n",
    "    \n",
    "    Args:\n",
    "        gold: The set with the gold-standard values.\n",
    "        pred: The set with the predicted values.\n",
    "    \n",
    "    Returns:\n",
    "        Nothing, but prints the precision, recall, and F1 values computed\n",
    "        based on the specified sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    intersection = len(gold & pred)\n",
    "    \n",
    "    # Precision\n",
    "    precision = intersection/len(pred)\n",
    "    print(\"Precision: \", precision)\n",
    "      \n",
    "    # Recall\n",
    "    recall = intersection/len(gold)\n",
    "    print(\"Recall: \", recall)\n",
    "    \n",
    "    # F1 score\n",
    "    print(\"F1 score: \", 2 * precision * recall/(precision + recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your code, you can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.6\n",
      "Recall:  1.0\n",
      "F1 score:  0.7499999999999999\n"
     ]
    }
   ],
   "source": [
    "evaluation_report(set(range(3)), set(range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give you a precision of 60%, a recall of 100%, and an F1-value of 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Span recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first tasks that an information extraction system has to solve is to locate and classify (mentions of) named entities, such as persons and organizations. Here we will tackle the simpler task of recognizing **spans** of tokens that contain an entity mention, without the actual entity label.\n",
    "\n",
    "The English language model in spaCy features a full-fledged [named entity recognizer](https://spacy.io/usage/linguistic-features#named-entities) that identifies a variety of entities, and can be updated with new entity types by the user. Your task in this problem is to evaluate the performance of this component when predicting entity spans in the development data.\n",
    "\n",
    "Start by implementing a generator function that yields the gold-standard spans in a given data frame.\n",
    "\n",
    "**Hint:** The Pandas method [`itertuples()`](https://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.itertuples.html) is useful when iterating over the rows in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_spans(df):\n",
    "    \"\"\"Yield the gold-standard mention spans in a data frame.\n",
    "\n",
    "    Args:\n",
    "        df: A data frame.\n",
    "\n",
    "    Yields:\n",
    "        The gold-standard mention spans in the specified data frame as\n",
    "        triples consisting of the sentence id, start position, and end\n",
    "        position of each span.\n",
    "    \"\"\"\n",
    "    for row in df.itertuples(False):\n",
    "        yield (row[0], row[2], row[3])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your code, you can count the spans yielded by your function. When called on the development data, you should get a total of 5,917 unique triples. The first triple and the last triple should be\n",
    "\n",
    "    ('0946-000', 2, 3)\n",
    "    ('1161-010', 1, 3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5917\n"
     ]
    }
   ],
   "source": [
    "spans_dev_gold = set(gold_spans(df_dev))\n",
    "print(len(spans_dev_gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to write code that calls spaCy to predict the named entities in the development data, and to evaluate the accuracy of these predictions in terms of precision, recall, and F1. Print these scores using the function that you wrote for Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.5213954072029113\n",
      "Recall:  0.702213959776914\n",
      "F1 score:  0.5984444764511019\n"
     ]
    }
   ],
   "source": [
    "pred = set()\n",
    "for row in df_dev.itertuples(False):\n",
    "    for ent in nlp(row[1]).ents:\n",
    "        pred.add((row[0], ent.start, ent.end))\n",
    "        \n",
    "evaluation_report(spans_dev_gold, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you were able to see in Problem&nbsp;2, the span accuracy of the named entity recognizer is far from perfect. In particular, only slightly more than half of the predicted spans are correct according to the gold standard. Your next task is to analyse this result in more detail.\n",
    "\n",
    "Here is a function that prints the false positives as well as the false negatives spans for a data frame, given a reference set of gold-standard spans and a candidate set of predicted spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def error_report(df, spans_gold, spans_pred):\n",
    "    false_pos = defaultdict(list)\n",
    "    for s, b, e in spans_pred - spans_gold:\n",
    "        false_pos[s].append((b, e))\n",
    "    false_neg = defaultdict(list)\n",
    "    for s, b, e in spans_gold - spans_pred:\n",
    "        false_neg[s].append((b, e))\n",
    "    for row in df.drop_duplicates('sentence_id').itertuples():\n",
    "        if row.sentence_id in false_pos or row.sentence_id in false_neg:\n",
    "            print('Sentence:', row.sentence)\n",
    "            for b, e in false_pos[row.sentence_id]:\n",
    "                print('  FP:', ' '.join(row.sentence.split()[b:e]))\n",
    "            for b, e in false_neg[row.sentence_id]:\n",
    "                print('  FN:', ' '.join(row.sentence.split()[b:e]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to inspect and analyse the errors that the automated prediction makes. Can you see any patterns? Base your analysis on the first 500 rows of the training data. Summarize your observations in a short text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: CRICKET - LEICESTERSHIRE TAKE OVER AT TOP AFTER INNINGS VICTORY .\n",
      "  FN: LEICESTERSHIRE\n",
      "Sentence: LONDON 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: West Indian all-rounder Phil Simmons took four for 38 on Friday as Leicestershire beat Somerset by an innings and 39 runs in two days to take over at the head of the county championship .\n",
      "  FP: 39\n",
      "  FP: two days\n",
      "  FP: Friday\n",
      "  FP: four\n",
      "  FP: 38\n",
      "Sentence: After bowling Somerset out for 83 on the opening morning at Grace Road , Leicestershire extended their first innings by 94 runs before being bowled out for 296 with England discard Andy Caddick taking three for 83 .\n",
      "  FP: 83\n",
      "  FP: 94\n",
      "  FP: the opening morning\n",
      "  FP: 296\n",
      "  FP: first\n",
      "  FP: three\n",
      "  FP: 83\n",
      "Sentence: Trailing by 213 , Somerset got a solid start to their second innings before Simmons stepped in to bundle them out for 174 .\n",
      "  FP: 174\n",
      "  FP: 213\n",
      "  FP: second\n",
      "Sentence: Essex , however , look certain to regain their top spot after Nasser Hussain and Peter Such gave them a firm grip on their match against Yorkshire at Headingley .\n",
      "  FP: Yorkshire at\n",
      "  FN: Yorkshire\n",
      "  FN: Essex\n",
      "Sentence: Hussain , considered surplus to England 's one-day requirements , struck 158 , his first championship century of the season , as Essex reached 372 and took a first innings lead of 82 .\n",
      "  FP: 158\n",
      "  FP: one-day\n",
      "  FP: first\n",
      "  FP: 372\n",
      "  FP: 82\n",
      "  FP: first\n",
      "Sentence: By the close Yorkshire had turned that into a 37-run advantage but off-spinner Such had scuttled their hopes , taking four for 24 in 48 balls and leaving them hanging on 119 for five and praying for rain .\n",
      "  FP: 119\n",
      "  FP: four\n",
      "  FP: 24\n",
      "  FP: 48\n",
      "  FP: five\n",
      "  FN: Such\n",
      "Sentence: At the Oval , Surrey captain Chris Lewis , another man dumped by England , continued to silence his critics as he followed his four for 45 on Thursday with 80 not out on Friday in the match against Warwickshire .\n",
      "  FP: Thursday\n",
      "  FP: 80\n",
      "  FP: Friday\n",
      "  FP: four\n",
      "  FP: 45\n",
      "Sentence: He was well backed by England hopeful Mark Butcher who made 70 as Surrey closed on 429 for seven , a lead of 234 .\n",
      "  FP: 70\n",
      "  FP: 429\n",
      "  FP: seven\n",
      "  FP: 234\n",
      "Sentence: Derbyshire kept up the hunt for their first championship title since 1936 by reducing Worcestershire to 133 for five in their second innings , still 100 runs away from avoiding an innings defeat .\n",
      "  FP: first\n",
      "  FP: 133\n",
      "  FP: 1936\n",
      "  FP: second\n",
      "  FP: five\n",
      "  FP: 100\n",
      "  FN: Derbyshire\n",
      "Sentence: Australian Tom Moody took six for 82 but Chris Adams , 123 , and Tim O'Gorman , 109 , took Derbyshire to 471 and a first innings lead of 233 .\n",
      "  FP: 123\n",
      "  FP: 109\n",
      "  FP: six\n",
      "  FP: 82\n",
      "  FP: 471\n",
      "  FP: 233\n",
      "  FP: first\n",
      "Sentence: After the frustration of seeing the opening day of their match badly affected by the weather , Kent stepped up a gear to dismiss Nottinghamshire for 214 .\n",
      "  FP: 214\n",
      "Sentence: They were held up by a gritty 84 from Paul Johnson but ex-England fast bowler Martin McCague took four for 55 .\n",
      "  FP: four\n",
      "  FP: 55\n",
      "  FP: 84\n",
      "  FN: ex-England\n",
      "Sentence: By stumps Kent had reached 108 for three .\n",
      "  FP: 108\n",
      "  FP: three\n",
      "Sentence: CRICKET - ENGLISH COUNTY CHAMPIONSHIP SCORES .\n",
      "  FP: CRICKET - ENGLISH COUNTY CHAMPIONSHIP SCORES\n",
      "  FN: ENGLISH COUNTY CHAMPIONSHIP\n",
      "Sentence: LONDON 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: Result and close of play scores in English county championship matches on Friday :\n",
      "  FP: English county\n",
      "  FP: Friday\n",
      "  FN: English\n",
      "Sentence: Leicester : Leicestershire beat Somerset by an innings and 39 runs .\n",
      "  FP: 39\n",
      "  FN: Leicestershire\n",
      "  FN: Leicester\n",
      "Sentence: Somerset 83 and 174 ( P. Simmons 4-38 ) , Leicestershire 296 .\n",
      "  FP: 174\n",
      "  FP: 83\n",
      "  FP: 296\n",
      "  FN: Somerset\n",
      "  FN: Leicestershire\n",
      "  FN: P. Simmons\n",
      "Sentence: Leicestershire 22 points , Somerset 4 .\n",
      "  FP: 22\n",
      "  FP: 4\n",
      "  FN: Leicestershire\n",
      "  FN: Somerset\n",
      "Sentence: Chester-le-Street : Glamorgan 259 and 207 ( A. Dale 69 , H. Morris 69 ; D. Blenkiron 4-43 ) , Durham 114 ( S. Watkin 4-28 ) and 81-3 .\n",
      "  FP: 4-28\n",
      "  FP: 259\n",
      "  FP: D.\n",
      "  FP: H. Morris 69\n",
      "  FP: 81-3\n",
      "  FN: H. Morris\n",
      "  FN: Chester-le-Street\n",
      "  FN: S. Watkin\n",
      "  FN: A. Dale\n",
      "  FN: D. Blenkiron\n",
      "Sentence: Tunbridge Wells : Nottinghamshire 214 ( P. Johnson 84 ; M. McCague 4-55 ) , Kent 108-3 .\n",
      "  FP: M. McCague 4-55\n",
      "  FN: Kent\n",
      "  FN: M. McCague\n",
      "  FN: Nottinghamshire\n",
      "  FN: P. Johnson\n",
      "Sentence: London ( The Oval ) : Warwickshire 195 , Surrey 429-7 ( C. Lewis 80 not out , M. Butcher 70 , G. Kersey 63 , J. Ratcliffe 63 , D. Bicknell 55 ) .\n",
      "  FP: Surrey 429-7\n",
      "  FP: D.\n",
      "  FP: G. Kersey 63\n",
      "  FP: J. Ratcliffe 63\n",
      "  FP: 55\n",
      "  FP: 195\n",
      "  FN: C. Lewis\n",
      "  FN: Warwickshire\n",
      "  FN: J. Ratcliffe\n",
      "  FN: G. Kersey\n",
      "  FN: Surrey\n",
      "  FN: D. Bicknell\n",
      "  FN: The Oval\n",
      "Sentence: Hove : Sussex 363 ( W. Athey 111 , V. Drakes 52 ; I. Austin 4-37 ) , Lancashire 197-8 ( W. Hegg 54 )\n",
      "  FP: V. Drakes 52\n",
      "  FP: Lancashire 197-8\n",
      "  FP: I. Austin 4-37\n",
      "  FP: W. Hegg 54\n",
      "  FP: W. Athey 111\n",
      "  FN: Lancashire\n",
      "  FN: I. Austin\n",
      "  FN: Hove\n",
      "  FN: V. Drakes\n",
      "  FN: W. Hegg\n",
      "  FN: Sussex\n",
      "  FN: W. Athey\n",
      "Sentence: Portsmouth : Middlesex 199 and 426 ( J. Pooley 111 , M. Ramprakash 108 , M. Gatting 83 ) , Hampshire 232 and 109-5 .\n",
      "  FP: Hampshire 232\n",
      "  FP: 199\n",
      "  FP: 109-5\n",
      "  FP: 426\n",
      "  FP: J. Pooley 111\n",
      "  FP: M. Gatting 83\n",
      "  FP: M. Ramprakash 108\n",
      "  FN: Portsmouth\n",
      "  FN: Middlesex\n",
      "  FN: J. Pooley\n",
      "  FN: Hampshire\n",
      "  FN: M. Gatting\n",
      "  FN: M. Ramprakash\n",
      "Sentence: Chesterfield : Worcestershire 238 and 133-5 , Derbyshire 471 ( J. Adams 123 , T.O'Gorman 109 not out , K. Barnett 87 ; T. Moody 6-82 )\n",
      "  FP: 109\n",
      "  FP: J. Adams 123\n",
      "  FP: Worcestershire 238 and 133-5\n",
      "  FP: T. Moody 6-82\n",
      "  FN: T.O'Gorman\n",
      "  FN: J. Adams\n",
      "  FN: Worcestershire\n",
      "  FN: Derbyshire\n",
      "  FN: T. Moody\n",
      "Sentence: Bristol : Gloucestershire 183 and 185-6 ( J. Russell 56 not out ) , Northamptonshire 190 ( K. Curran 52 ; A. Smith 5-68 ) .\n",
      "  FP: 183\n",
      "  FP: J. Russell 56\n",
      "  FP: A. Smith 5-68\n",
      "  FP: Northamptonshire 190 ( K. Curran 52\n",
      "  FN: Northamptonshire\n",
      "  FN: J. Russell\n",
      "  FN: K. Curran\n",
      "  FN: A. Smith\n",
      "  FN: Gloucestershire\n",
      "Sentence: CRICKET - 1997 ASHES INTINERARY .\n",
      "  FP: CRICKET - 1997\n",
      "  FN: ASHES\n",
      "Sentence: LONDON 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: Australia will defend the Ashes in\n",
      "  FN: Ashes\n",
      "Sentence: a six-test series against England during a four-month tour\n",
      "  FP: four-month\n",
      "Sentence: starting on May 13 next year , the Test and County Cricket Board\n",
      "  FP: May 13 next year\n",
      "  FN: Test and County Cricket Board\n",
      "Sentence: Australia will also play three one-day internationals and\n",
      "  FP: three\n",
      "Sentence: as well as one-day matches against the Minor Counties and\n",
      "  FP: one-day\n",
      "  FN: Minor Counties\n",
      "Sentence: May 13 Arrive in London\n",
      "  FP: May 13 Arrive\n",
      "Sentence: May 14 Practice at Lord 's\n",
      "  FP: May 14 Practice\n",
      "  FN: Lord 's\n",
      "Sentence: May 15 v Duke of Norfolk 's XI ( at Arundel )\n",
      "  FP: XI\n",
      "  FP: May 15 v Duke of Norfolk 's\n",
      "  FN: Arundel\n",
      "  FN: Duke of Norfolk 's XI\n",
      "Sentence: May 17 v Northampton\n",
      "  FP: May 17\n",
      "Sentence: May 18 v Worcestershire\n",
      "  FP: May 18 v\n",
      "  FN: Worcestershire\n",
      "Sentence: May 20 v Durham\n",
      "  FP: May 20\n",
      "  FN: Durham\n",
      "Sentence: May 22 First one-day international ( at Headingley ,\n",
      "  FP: May 22 First one-day\n",
      "Sentence: May 24 Second one-day international ( at The Oval ,\n",
      "  FP: May 24 Second\n",
      "Sentence: May 25 Third one-day international ( at Lord 's , London )\n",
      "  FP: May 25 Third one-day\n",
      "  FN: Lord 's\n",
      "Sentence: May 27-29 v Gloucestershire or Sussex or Surrey ( three\n",
      "  FP: May 27-29 v Gloucestershire\n",
      "  FP: three\n",
      "  FN: Gloucestershire\n",
      "Sentence: May 31 - June 2 v Derbyshire ( three days )\n",
      "  FP: May 31 - June 2 v Derbyshire\n",
      "  FP: three days\n",
      "  FN: Derbyshire\n",
      "Sentence: June 5-9 First test match ( at Edgbaston , Birmingham )\n",
      "  FP: First\n",
      "  FP: June 5-9\n",
      "Sentence: June 14-16 v Leicestershire ( three days )\n",
      "  FP: June 14-16\n",
      "  FP: three days\n",
      "  FN: Leicestershire\n",
      "Sentence: June 19-23 Second test ( at Lord 's )\n",
      "  FP: June 19-23\n",
      "  FP: Second\n",
      "  FN: Lord 's\n",
      "Sentence: June 25-27 v British Universities ( at Oxford , three days )\n",
      "  FP: June 25-27\n",
      "  FP: British\n",
      "  FP: three days\n",
      "  FN: British Universities\n",
      "Sentence: June 28-30 v Hampshire ( three days )\n",
      "  FP: June 28-30 v Hampshire\n",
      "  FP: three days\n",
      "  FN: Hampshire\n",
      "Sentence: July 3-7 Third test ( at Old Trafford , Manchester )\n",
      "  FP: July 3-7 Third\n",
      "Sentence: July 9 v Minor Counties XI\n",
      "  FP: July 9\n",
      "  FN: Minor Counties XI\n",
      "Sentence: July 12 v Scotland\n",
      "  FP: July 12\n",
      "Sentence: July 16-18 v Glamorgan ( three days )\n",
      "  FP: three days\n",
      "  FP: July 16-18\n",
      "  FN: Glamorgan\n",
      "Sentence: July 19-21 v Middlesex ( three days )\n",
      "  FP: three days\n",
      "  FP: July 19-21\n",
      "  FN: Middlesex\n",
      "Sentence: July 24-28 Fourth test ( at Headingley )\n",
      "  FP: July 24-28\n",
      "  FP: Fourth\n",
      "Sentence: August 1-4 v Somerset ( four days )\n",
      "  FP: August 1-4\n",
      "  FP: four days\n",
      "  FN: Somerset\n",
      "Sentence: August 7-11 Fifth test ( at Trent Bridge , Nottingham )\n",
      "  FP: August 7-11 Fifth\n",
      "Sentence: August 16-18 v Kent ( three days )\n",
      "  FP: August 16-18\n",
      "  FP: three days\n",
      "  FN: Kent\n",
      "Sentence: August 21-25 Sixth test ( at The Oval , London ) .\n",
      "  FP: August 21-25\n",
      "  FP: Sixth\n",
      "Sentence: SOCCER - SHEARER NAMED AS ENGLAND CAPTAIN .\n",
      "  FN: SHEARER\n",
      "  FN: ENGLAND\n",
      "Sentence: LONDON 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: The world 's costliest footballer Alan Shearer was named as the new England captain on Friday .\n",
      "  FP: Friday\n",
      "Sentence: The 26-year-old , who joined Newcastle for 15 million pounds sterling ( $ 23.4 million ) , takes over from Tony Adams , who led the side during the European championship in June , and former captain David Platt .\n",
      "  FP: 15 million pounds\n",
      "  FP: June\n",
      "  FP: $ 23.4 million\n",
      "Sentence: Adams and Platt are both injured and will miss England 's opening World Cup qualifier against Moldova on Sunday .\n",
      "  FP: Sunday\n",
      "  FN: Adams\n",
      "Sentence: \" There were three or four people who could have done it but when I spoke to Alan he was up for it and really wanted it .\n",
      "  FP: three\n",
      "  FP: four\n",
      "Sentence: Shearer 's Euro 96 striking partner Teddy Sheringham withdrew from the squad with an injury on Friday .\n",
      "  FP: Friday\n",
      "Sentence: BELGRADE 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "  FN: BELGRADE\n",
      "Sentence: SOCCER - ROMANIA BEAT LITHUANIA IN UNDER-21 MATCH .\n",
      "  FN: ROMANIA\n",
      "  FN: LITHUANIA\n",
      "Sentence: BUCHAREST 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "  FN: BUCHAREST\n",
      "Sentence: Romania beat Lithuania 2-1 ( halftime 1-1 ) in their European under-21 soccer match on Friday .\n",
      "  FP: Friday\n",
      "  FP: 1-1\n",
      "Sentence: Romania - Cosmin Contra ( 31st ) , Mihai Tararache ( 75th )\n",
      "  FP: Romania - Cosmin Contra\n",
      "  FP: 75th\n",
      "  FN: Cosmin Contra\n",
      "  FN: Romania\n",
      "Sentence: Lithuania - Danius Gleveckas ( 13rd )\n",
      "  FN: Danius Gleveckas\n",
      "Sentence: SOCCER - ROTOR FANS LOCKED OUT AFTER VOLGOGRAD VIOLENCE .\n",
      "  FN: VOLGOGRAD\n",
      "  FN: ROTOR\n",
      "Sentence: MOSCOW 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: Rotor Volgograd must play their next home game behind closed doors after fans hurled bottles and stones at Dynamo Moscow players during a 1-0 home defeat on Saturday that ended Rotor 's brief spell as league leaders .\n",
      "  FP: Saturday\n",
      "  FP: Volgograd\n",
      "  FN: Rotor Volgograd\n",
      "  FN: Rotor\n",
      "Sentence: The head of the Russian league 's disciplinary committee , Anatoly Gorokhovsky , said on Friday that Rotor would play Lada Togliatti to empty stands on September 3 .\n",
      "  FP: Friday\n",
      "  FP: September 3\n",
      "  FP: the Russian league 's\n",
      "  FN: Rotor\n",
      "  FN: Russian\n",
      "Sentence: The club , who put Manchester United out of last year 's UEFA Cup , were fined $ 1,000 .\n",
      "  FP: last year 's\n",
      "  FP: 1,000\n",
      "Sentence: Despite the defeat , Rotor are well placed with 11 games to play in the championship .\n",
      "  FP: 11\n",
      "  FN: Rotor\n",
      "Sentence: Lying three points behind Alania and two behind Dynamo Moscow , the Volgograd side have a game in hand over the leaders and two over the Moscow club .\n",
      "  FP: two\n",
      "  FP: three\n",
      "  FP: two\n",
      "Sentence: BOXING - PANAMA 'S ROBERTO DURAN FIGHTS THE SANDS OF TIME .\n",
      "  FN: PANAMA\n",
      "  FN: ROBERTO DURAN\n",
      "Sentence: PANAMA CITY 1996-08-30\n",
      "  FP: PANAMA\n",
      "  FN: PANAMA CITY\n",
      "Sentence: Panamanian boxing legend Roberto \" Hands of Stone \" Duran climbs into the ring on Saturday in another age-defying attempt to sustain his long career .\n",
      "  FP: Saturday\n",
      "Sentence: Duran , 45 , takes on little-known Mexican Ariel Cruz , 30 , in a super middleweight non-title bout in Panama City .\n",
      "  FP: 30\n",
      "  FP: 45\n",
      "Sentence: The fight , Duran 's first on home soil for 10 years , is being billed here as the \" Return of the Legend \" and Duran still talks as if he was in his prime .\n",
      "  FP: first\n",
      "  FP: 10 years\n",
      "  FN: Return of the Legend\n",
      "Sentence: If he loses Saturday , it could devalue his position as one of the world 's great boxers , \" Panamanian Boxing Association President Ramon Manzanares said .\n",
      "  FP: Saturday\n",
      "  FN: Panamanian\n",
      "  FN: Boxing Association\n",
      "Sentence: Duran , whose 97-12 record spans three decades , hopes a win in the 10-round bout will earn him a rematch against Puerto Rico 's Hector \" Macho \" Camacho .\n",
      "  FP: 97-12\n",
      "  FP: three decades\n",
      "  FP: Puerto Rico 's\n",
      "  FN: Puerto Rico\n",
      "Sentence: Camacho took a controversial points decision against the Panamanian in Atlantic City in June in a title fight .\n",
      "  FP: June\n",
      "Sentence: SQUASH - HONG KONG OPEN QUARTER-FINAL RESULTS .\n",
      "  FP: SQUASH - HONG KONG OPEN\n",
      "  FN: HONG KONG OPEN\n",
      "Sentence: HONG KONG 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: Quarter-final results in the Hong Kong Open on Friday ( prefix number denotes seeding ) : 1 - Jansher Khan ( Pakistan ) beat Mark Cairns ( England ) 15-10 15-6 15-7\n",
      "  FP: 15-10 15-6\n",
      "  FP: 1\n",
      "  FP: the Hong Kong Open\n",
      "  FP: Friday\n",
      "  FN: Hong Kong Open\n",
      "  FN: Jansher Khan\n",
      "Sentence: Anthony Hill ( Australia ) beat Dan Jenson ( Australia ) 15-9 15-8 15-17 17-15\n",
      "  FP: 15-9\n",
      "Sentence: 4 - Peter Nicol ( Scotland ) beat 7 - Chris Walker ( England ) 15-8 15-13 13-15 15-9\n",
      "  FP: 7\n",
      "  FP: 4 - Peter Nicol\n",
      "  FP: 15-8 15-13\n",
      "  FN: Peter Nicol\n",
      "  FN: England\n",
      "  FN: Chris Walker\n",
      "Sentence: 2 - Rodney Eyles ( Australia ) beat Derek Ryan ( Ireland ) 15-6 15-9 11-15 15-10 .\n",
      "  FP: 2 - Rodney Eyles\n",
      "  FP: 15-6 15-9 11-15 15-10\n",
      "  FN: Ireland\n",
      "  FN: Rodney Eyles\n",
      "Sentence: SEOUL 1996-08-30\n",
      "  FP: SEOUL 1996-08-30\n",
      "  FN: SEOUL\n",
      "Sentence: Pohang 3 Ulsan 2 ( halftime 1-0 )\n",
      "  FP: Pohang 3 Ulsan 2\n",
      "  FN: Ulsan\n",
      "  FN: Pohang\n",
      "Sentence: Puchon 2 Chonbuk 1 ( halftime 1-1 )\n",
      "  FP: 2\n",
      "  FP: 1-1\n",
      "  FN: Puchon\n",
      "  FN: Chonbuk\n",
      "Sentence: Puchon 3 1 0 6 1 10\n",
      "  FP: 3 1 0 6 1 10\n",
      "  FN: Puchon\n",
      "Sentence: Chonan 3 0 1 13 10 9\n",
      "  FP: 9\n",
      "  FN: Chonan\n",
      "Sentence: Pohang 2 1 1 11 10 7\n",
      "  FP: Pohang 2 1 1 11\n",
      "  FN: Pohang\n",
      "Sentence: Suwan 1 3 0 7 3 6\n",
      "  FN: Suwan\n",
      "Sentence: Ulsan 1 0 2 8 9 3\n",
      "  FN: Ulsan\n",
      "Sentence: Anyang 0 3 1 6 9 3\n",
      "  FP: 0 3 1 6 9 3\n",
      "  FN: Anyang\n",
      "Sentence: Pusan 0 2 1 3 7 2\n",
      "  FP: Pusan 0 2 1 3\n",
      "  FN: Pusan\n",
      "Sentence: Chonbuk 0 0 3 3 7 0\n",
      "  FP: 0\n",
      "  FN: Chonbuk\n",
      "Sentence: SEOUL 1996-08-30\n",
      "  FP: SEOUL 1996-08-30\n",
      "  FN: SEOUL\n",
      "Sentence: LG 2 OB 0\n",
      "  FP: 2\n",
      "  FN: OB\n",
      "  FN: LG\n",
      "Sentence: Lotte 6 Hyundai 2\n",
      "  FP: 2\n",
      "  FN: Lotte\n",
      "Sentence: Hyundai 6 Lotte 5\n",
      "  FP: 6 Lotte 5\n",
      "  FN: Lotte\n",
      "Sentence: Haitai 2 Samsung 0\n",
      "  FP: Haitai 2 Samsung 0\n",
      "  FN: Haitai\n",
      "  FN: Samsung\n",
      "Sentence: Samsung 10 Haitai 3\n",
      "  FP: 3\n",
      "  FN: Haitai\n",
      "Sentence: Hanwha 6 Ssangbangwool 5\n",
      "  FP: 6\n",
      "  FP: 5\n",
      "  FN: Hanwha\n",
      "  FN: Ssangbangwool\n",
      "Sentence: Note - Lotte and Hyundai , Haitai and Samsung played two games .\n",
      "  FP: two\n",
      "  FN: Lotte\n",
      "Sentence: Haitai 64 2 43 .596 -\n",
      "  FP: 64 2 43\n",
      "  FN: Haitai\n",
      "Sentence: Ssangbangwool 59 2 49 .545 5 1/2\n",
      "  FP: .545 5 1/2\n",
      "  FN: Ssangbangwool\n",
      "Sentence: Hanwha 58 1 49 .542 6\n",
      "  FP: 58\n",
      "  FP: 49\n",
      "  FP: 6\n",
      "Sentence: Hyundai 57 5 49 .536 6 1/2\n",
      "  FP: 57\n",
      "  FP: 5 49 .536 6 1/2\n",
      "Sentence: Samsung 49 5 56 .468 14\n",
      "  FP: 14\n",
      "Sentence: Lotte 46 6 54 .462 14 1/2\n",
      "  FP: 14 1/2\n",
      "  FN: Lotte\n",
      "Sentence: LG 46 5 59 .441 17\n",
      "  FP: 17\n",
      "  FP: 46\n",
      "  FN: LG\n",
      "Sentence: OB 42 6 62 .409 20 1/2\n",
      "  FP: 42\n",
      "  FP: 20 1/2\n",
      "  FN: OB\n",
      "Sentence: TENNIS - FRIDAY 'S RESULTS FROM THE U.S. OPEN .\n",
      "  FP: U.S.\n",
      "  FN: U.S. OPEN\n",
      "Sentence: NEW YORK 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: Results from the U.S. Open Tennis Championships at the National Tennis Centre on Friday ( prefix number denotes seeding ) :\n",
      "  FP: the U.S. Open Tennis Championships\n",
      "  FP: the National Tennis Centre\n",
      "  FP: Friday\n",
      "  FN: National Tennis Centre\n",
      "  FN: U.S. Open Tennis Championships\n",
      "Sentence: Sandrine Testud ( France ) beat Ines Gorrochategui ( Argentina ) 4-6 6-2 6-1\n",
      "  FP: 4-6\n",
      "  FP: 6-1\n",
      "Sentence: 4 - Goran Ivanisevic ( Croatia ) beat Scott Draper ( Australia ) 6-7 ( 1-7 ) 6-3 6-4 6-4\n",
      "  FP: Scott Draper ( Australia\n",
      "  FP: 6-7\n",
      "  FP: 1-7\n",
      "  FP: 6-3\n",
      "  FP: 4\n",
      "  FN: Australia\n",
      "  FN: Croatia\n",
      "  FN: Goran Ivanisevic\n",
      "  FN: Scott Draper\n",
      "Sentence: Tim Henman ( Britain ) beat Doug Flach ( U.S. ) 6-3 6-4 6-2\n",
      "  FP: 6-3\n",
      "Sentence: Mark Philippoussis ( Australia ) beat Andrei Olhovskiy ( Russia ) 6 - 3 6-4 6-2\n",
      "  FP: 6 - 3 6-4 6-2\n",
      "Sentence: Sjeng Schalken ( Netherlands ) beat David Rikl ( Czech Republic ) 6 - 2 6-4 6-4\n",
      "  FP: 6 - 2 6-4 6-4\n",
      "Sentence: Guy Forget ( France ) beat 17 - Felix Mantilla ( Spain ) 6-4 7-5 6-3\n",
      "  FP: 17\n",
      "  FP: 6-3\n",
      "  FP: 6-4 7-5\n",
      "  FN: Felix Mantilla\n",
      "Sentence: Alexander Volkov ( Russia ) beat Mikael Tillstrom ( Sweden ) 1-6 6- 4 6-1 4-6 7-6 ( 10-8 )\n",
      "  FP: 10-8\n",
      "  FP: 1-6\n",
      "Sentence: Jonas Bjorkman ( Sweden ) beat David Nainkin ( South Africa ) ) 6-4 6-1 6-1\n",
      "  FP: 6-4\n",
      "Sentence: 8 - Lindsay Davenport ( U.S. ) beat Anne-Gaelle Sidot ( France ) 6-0 6-3\n",
      "  FP: 8\n",
      "  FP: Sidot\n",
      "  FP: 6-0 6-3\n",
      "  FN: Anne-Gaelle Sidot\n",
      "  FN: Lindsay Davenport\n",
      "Sentence: 4 - Conchita Martinez ( Spain ) beat Helena Sukova ( Czech Republic ) 6-4 6-3\n",
      "  FP: 6-4 6-3\n",
      "  FP: 4\n",
      "  FN: Conchita Martinez\n",
      "Sentence: Amanda Coetzer ( South Africa ) beat Irina Spirlea ( Romania ) 7-6 ( 7-5 ) 7-5\n",
      "  FP: 7-5\n",
      "Sentence: Add Men 's singles , second round 16 - Cedric Pioline ( France ) beat Roberto Carretero ( Spain ) 4-6 6 - 2 6-2 6-1 Alex Corretja ( Spain ) beat Filippo Veglio ( Switzerland ) 6-7 ( 4- 7 ) 6-4 6-4 6-0\n",
      "  FP: second\n",
      "  FP: 16\n",
      "  FP: 6-7\n",
      "  FP: 7\n",
      "  FP: 4-6\n",
      "  FN: Cedric Pioline\n",
      "Sentence: Add Women 's singles , third round Linda Wild ( U.S. ) beat Barbara Rittner ( Germany ) 6-4 4-6 7-5 Asa Carlsson ( Sweden ) beat 15 - Gabriela Sabatini ( Argentina ) 7-5 3-6 6-2\n",
      "  FP: 7-5 Asa Carlsson\n",
      "  FP: 6-4 4-6\n",
      "  FP: 15 - Gabriela Sabatini\n",
      "  FP: third\n",
      "  FP: 3-6\n",
      "  FP: 6-2\n",
      "  FN: Gabriela Sabatini\n",
      "  FN: Asa Carlsson\n",
      "Sentence: Add Men 's singles , second round 1 - Pete Sampras ( U.S. ) beat Jiri Novak ( Czech Republic ) 6-3 1-6 6-3 4-6 6-4 Paul Haarhuis ( Netherlands ) beat Michael Tebbutt ( Australia ) 1- 6 6-2 6-2 6-3\n",
      "  FP: second\n",
      "  FP: 6-2 6-3\n",
      "  FP: 1 - Pete Sampras\n",
      "  FP: 6 6-2\n",
      "  FP: 1-6 6-3 4-6\n",
      "  FP: 6-3\n",
      "  FN: Pete Sampras\n",
      "Sentence: Add Women 's singles , third round Lisa Raymond ( U.S. ) beat Kimberly Po ( U.S. ) 6-3 6-2\n",
      "  FP: 6-3\n",
      "  FP: third\n",
      "Sentence: Andrei Medvedev ( Ukraine ) beat Jan Kroslak ( Slovakia ) 6-4 6-3\n",
      "  FP: 6-4 6-3\n",
      "Sentence: Petr Korda ( Czech Republic ) bat Bohdan Ulihrach ( Czech Republic ) 6-0 7-6 ( 7-5 ) 6-2\n",
      "  FP: 6-2\n",
      "  FN: Petr Korda\n",
      "Sentence: 2 - Monica Seles ( U.S. ) beat Dally Randriantefy ( Madagascar )\n",
      "  FP: 2\n",
      "  FP: Dally Randriantefy ( Madagascar\n",
      "  FN: Madagascar\n",
      "  FN: Monica Seles\n",
      "  FN: Dally Randriantefy\n",
      "Sentence: Add men 's singles , second round 12 - Todd Martin ( U.S. ) beat Andrea Gaudenzi ( Italy ) 6-3 6-2 6-2 Stefan Edberg ( Sweden ) beat Bernd Karbacher ( Germany ) 3-6 6-3 6-3 1-0 retired ( leg injury )\n",
      "  FP: 6-3\n",
      "  FP: 3-6\n",
      "  FP: 6-3\n",
      "  FP: second\n",
      "  FP: 12\n",
      "Sentence: BASEBALL - MAJOR LEAGUE STANDINGS AFTER THURSDAY 'S GAMES .\n",
      "  FN: MAJOR LEAGUE\n",
      "Sentence: NEW YORK 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: AMERICAN LEAGUE EASTERN DIVISION\n",
      "  FP: AMERICAN LEAGUE EASTERN\n",
      "  FN: AMERICAN LEAGUE EASTERN DIVISION\n",
      "Sentence: NEW YORK 74 59 .556 -\n",
      "  FP: 74 59\n",
      "Sentence: BALTIMORE 70 63 .526 4\n",
      "  FP: 4\n",
      "  FP: BALTIMORE 70 63\n",
      "  FN: BALTIMORE\n",
      "Sentence: BOSTON 69 65 .515 5 1/2\n",
      "  FP: 5 1/2\n",
      "  FP: BOSTON 69 65\n",
      "  FN: BOSTON\n",
      "Sentence: TORONTO 63 71 .470 11 1/2\n",
      "  FP: 11 1/2\n",
      "  FP: 63 71\n",
      "Sentence: DETROIT 48 86 .358 26 1/2\n",
      "  FP: 48 86\n",
      "  FP: 26 1/2\n",
      "Sentence: CENTRAL DIVISION\n",
      "  FN: CENTRAL DIVISION\n",
      "Sentence: CLEVELAND 80 53 .602 -\n",
      "  FP: CLEVELAND 80 53\n",
      "  FP: .602\n",
      "  FN: CLEVELAND\n",
      "Sentence: CHICAGO 71 64 .526 10\n",
      "  FP: 10\n",
      "  FN: CHICAGO\n",
      "Sentence: MINNESOTA 67 67 .500 13 1/2\n",
      "  FP: 67 67\n",
      "  FP: 13 1/2\n",
      "  FN: MINNESOTA\n",
      "Sentence: MILWAUKEE 64 71 .474 17\n",
      "  FP: 64 71\n",
      "  FP: 17\n",
      "  FN: MILWAUKEE\n",
      "Sentence: KANSAS CITY 61 74 .452 20\n",
      "  FP: 20\n",
      "Sentence: WESTERN DIVISION\n",
      "  FN: WESTERN DIVISION\n",
      "Sentence: TEXAS 75 58 .564 -\n",
      "  FP: 75 58\n",
      "Sentence: SEATTLE 70 63 .526 5\n",
      "  FP: 5\n",
      "  FP: 70 63\n",
      "Sentence: OAKLAND 64 72 .471 12 1/2\n",
      "  FP: .471\n",
      "  FP: 12 1/2\n",
      "  FP: OAKLAND 64 72\n",
      "  FN: OAKLAND\n",
      "Sentence: CALIFORNIA 62 72 .463 13 1/2\n",
      "  FP: 13 1/2\n",
      "  FP: CALIFORNIA 62 72\n",
      "  FN: CALIFORNIA\n",
      "Sentence: CHICAGO AT TORONTO\n",
      "  FN: CHICAGO\n",
      "Sentence: MINNESOTA AT MILWAUKEE\n",
      "  FN: MINNESOTA\n",
      "  FN: MILWAUKEE\n",
      "Sentence: CLEVELAND AT TEXAS\n",
      "  FP: CLEVELAND AT\n",
      "  FN: TEXAS\n",
      "  FN: CLEVELAND\n",
      "Sentence: NATIONAL LEAGUE EASTERN DIVISION\n",
      "  FP: NATIONAL LEAGUE EASTERN\n",
      "  FN: NATIONAL LEAGUE EASTERN DIVISION\n",
      "Sentence: ATLANTA 83 49 .629 -\n",
      "  FP: 83\n",
      "Sentence: MONTREAL 71 61 .538 12\n",
      "  FP: 12\n",
      "  FP: 71 61\n",
      "  FN: MONTREAL\n",
      "Sentence: FLORIDA 64 70 .478 20\n",
      "  FP: 64 70\n",
      "  FP: 20\n",
      "Sentence: NEW YORK 59 75 .440 25\n",
      "  FP: 25\n",
      "  FP: 59 75\n",
      "Sentence: PHILADELPHIA 54 80 .403 30\n",
      "  FP: 30\n",
      "Sentence: CENTRAL DIVISION\n",
      "  FN: CENTRAL DIVISION\n",
      "Sentence: HOUSTON 72 63 .533 -\n",
      "  FP: .533 -\n",
      "  FP: HOUSTON 72 63\n",
      "  FN: HOUSTON\n",
      "Sentence: ST LOUIS 69 65 .515 2 1/2\n",
      "  FP: 2 1/2\n",
      "Sentence: CINCINNATI 66 67 .496 5\n",
      "  FP: 5\n",
      "  FP: 66 67\n",
      "Sentence: CHICAGO 65 66 .496 5\n",
      "  FP: 65 66 .496 5\n",
      "  FN: CHICAGO\n",
      "Sentence: PITTSBURGH 56 77 .421 15\n",
      "  FP: 56 77\n",
      "  FP: 15\n",
      "Sentence: WESTERN DIVISION\n",
      "  FN: WESTERN DIVISION\n",
      "Sentence: SAN DIEGO 75 60 .556 -\n",
      "  FP: SAN\n",
      "  FP: 75 60\n",
      "  FN: SAN DIEGO\n",
      "Sentence: LOS ANGELES 72 61 .541 2\n",
      "  FP: 2\n",
      "Sentence: COLORADO 70 65 .519 5\n",
      "  FP: 5\n",
      "  FP: 70 65\n",
      "Sentence: SAN FRANCISCO 57 74 .435 16\n",
      "  FP: 16\n",
      "  FP: 57 74\n",
      "Sentence: SAN DIEGO AT MONTREAL\n",
      "  FP: SAN\n",
      "  FN: SAN DIEGO\n",
      "  FN: MONTREAL\n",
      "Sentence: HOUSTON AT PITTSBURGH\n",
      "  FN: PITTSBURGH\n",
      "Sentence: SAN FRANCISCO AT NEW YORK\n",
      "  FN: NEW YORK\n",
      "Sentence: BASEBALL - MAJOR LEAGUE RESULTS THURSDAY .\n",
      "  FN: MAJOR LEAGUE\n",
      "Sentence: NEW YORK 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: DETROIT 4 Kansas City 1\n",
      "  FP: 4\n",
      "  FP: Kansas\n",
      "  FN: Kansas City\n",
      "Sentence: Minnesota 6 MILWAUKEE 1\n",
      "  FP: 6\n",
      "  FP: 1\n",
      "  FN: MILWAUKEE\n",
      "Sentence: CALIFORNIA 14 New York 3\n",
      "  FP: 14\n",
      "  FP: 3\n",
      "Sentence: SEATTLE 9 Baltimore 6\n",
      "  FP: 9\n",
      "  FP: 6\n",
      "Sentence: San Diego 3 NEW YORK 2\n",
      "  FP: 3\n",
      "  FP: 2\n",
      "Sentence: Chicago 4 HOUSTON 3\n",
      "  FP: 4\n",
      "  FP: 3\n",
      "  FN: HOUSTON\n",
      "Sentence: Cincinnati 18 COLORADO 7\n",
      "  FP: 18\n",
      "  FP: 7\n",
      "  FN: COLORADO\n",
      "Sentence: Atlanta 5 PITTSBURGH 1\n",
      "  FP: 5\n",
      "  FP: 1\n",
      "  FN: PITTSBURGH\n",
      "Sentence: Los Angeles 2 MONTREAL 1\n",
      "  FP: Los Angeles 2\n",
      "  FP: 1\n",
      "  FN: Los Angeles\n",
      "  FN: MONTREAL\n",
      "Sentence: Florida 10 ST LOUIS 9\n",
      "  FP: 10\n",
      "  FP: ST LOUIS 9\n",
      "  FN: ST LOUIS\n",
      "Sentence: TENNIS - TARANGO , O'BRIEN SPRING TWIN UPSETS UNDER THE LIGHTS .\n",
      "  FP: SPRING TWIN UPSETS\n",
      "  FN: O'BRIEN\n",
      "  FN: TARANGO\n",
      "Sentence: NEW YORK 1996-08-30\n",
      "  FP: 1996-08-30\n",
      "Sentence: Andre Agassi escaped disaster on Thursday but Wimbledon finalist MaliVai Washington and Marcelo Rios were not so fortunate on a night of upsets at the U.S. Open .\n",
      "  FP: MaliVai\n",
      "  FP: the U.S. Open\n",
      "  FP: Thursday\n",
      "  FP: Washington\n",
      "  FP: a night\n",
      "  FN: U.S. Open\n",
      "  FN: MaliVai Washington\n",
      "Sentence: The 11th-seeded Washington fell short of reprising his Wimbledon miracle comeback as he lost to red-hot wildcard Alex O'Brien 6-3 6-4 5-7 3-6 6-3 in a two hour 51 minute struggle on the Stadium court .\n",
      "  FP: a two hour 51 minute\n",
      "  FP: 6-4 5-7 3-6\n",
      "  FP: 11th-seeded\n"
     ]
    }
   ],
   "source": [
    "error_report(df_dev.iloc[0:500], spans_dev_gold, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the false positives were due to spaCy recognising numbers (both as text and numbers) as names, while most of the false negatives were due to spaCy not recognising certain names of cities and not being able to recognise abbreveations of peoples names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the insights from your error analysis to improve the automated prediction that you implemented in Problem&nbsp;2. While the best way to do this would be to [update spaCy&rsquo;s NER model](https://spacy.io/usage/linguistic-features#updating) using domain-specific training data, for this lab it suffices to write code to post-process the output produced by spaCy. To filter out specific labels it is useful to know the named entity label scheme, which can be found in the [model's documentation](https://spacy.io/models/en#en_core_web_sm). You should be able to improve the F1 score from Problem&nbsp;2 by at last 15 percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.857233771743742\n",
      "Recall:  0.6829474395808687\n",
      "F1 score:  0.7602295174489699\n"
     ]
    }
   ],
   "source": [
    "keep = {\"GPE\", \"ORG\", \"PERSON\", \"EVENT\", \"NORP\", \"LANGUAGE\"}\n",
    "\n",
    "pred_filter = set()\n",
    "for row in df_dev.itertuples(False):\n",
    "    for ent in nlp(row[1]).ents:\n",
    "        if ent.label_ in keep:\n",
    "            pred_filter.add((row[0], ent.start, ent.end))\n",
    "\n",
    "\n",
    "evaluation_report(spans_dev_gold, pred_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show that you achieve the performance goal by reporting the evaluation measures that you implemented in Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going on, we ask you to store the outputs of the improved named entity recognizer on the development data in a new data frame. This new frame should have the same layout as the original data frame for the development data that you loaded above, but should contain the *predicted* start and end positions for each token span, rather than the gold positions. As the `label` of each span, you can use the special value `--NME--`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1009-014</td>\n",
       "      <td>Mexican growers and distributors would have to...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1063-002</td>\n",
       "      <td>Ukraine beat Northern Ireland 1-0 ( halftime 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1082-002</td>\n",
       "      <td>Azerbaijan beat Switzerland 1-0 ( halftime 1-0...</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1096-023</td>\n",
       "      <td>Cubs shortstop Jose Hernandez committed three ...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0958-029</td>\n",
       "      <td>BOSTON AT OAKLAND</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>--NME--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id                                           sentence  beg  end  \\\n",
       "0    1009-014  Mexican growers and distributors would have to...   14   15   \n",
       "1    1063-002  Ukraine beat Northern Ireland 1-0 ( halftime 0...    0    1   \n",
       "2    1082-002  Azerbaijan beat Switzerland 1-0 ( halftime 1-0...   13   14   \n",
       "3    1096-023  Cubs shortstop Jose Hernandez committed three ...    2    4   \n",
       "4    0958-029                                  BOSTON AT OAKLAND    0    1   \n",
       "\n",
       "     label  \n",
       "0  --NME--  \n",
       "1  --NME--  \n",
       "2  --NME--  \n",
       "3  --NME--  \n",
       "4  --NME--  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_pred = pd.DataFrame(data=pred_filter, columns=[\"sentence_id\", \"beg\", \"end\"])\n",
    "df_dev_pred[\"label\"] = \"--NME--\"\n",
    "df_dev_pred[\"sentence\"] = df_dev_pred[\"sentence_id\"].apply(lambda x: df_dev.loc[df_dev[\"sentence_id\"] == x].iloc[0][1])\n",
    "\n",
    "df_dev_pred = df_dev_pred[[\"sentence_id\", \"sentence\", \"beg\", \"end\", \"label\"]]\n",
    "\n",
    "df_dev_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Entity linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a method for predicting mention spans, we turn to the task of **entity linking**, which amounts to predicting the knowledge base entity that is referenced by a given mention. In our case, for each span we want to predict the Wikipedia page that this mention references.\n",
    "\n",
    "Start by extending the generator function that you implemented in Problem&nbsp;2 to labelled spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_mentions(df):\n",
    "    \"\"\"Yield the gold-standard mentions in a data frame.\n",
    "\n",
    "    Args:\n",
    "        df: A data frame.\n",
    "\n",
    "    Yields:\n",
    "        The gold-standard mention spans in the specified data frame as\n",
    "        quadruples consisting of the sentence id, start position, end\n",
    "        position and entity label of each span.\n",
    "    \"\"\"\n",
    "    for row in df.itertuples(False):\n",
    "        yield (row[0], row[2], row[3], row[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive baseline for entity linking on our data set is to link each mention span to the Wikipedia page name that we get when we join the tokens in the span by underscores, as is standard in Wikipedia page names. Suppose, for example, that a span contains the two tokens\n",
    "\n",
    "    Jimi Hendrix\n",
    "\n",
    "The baseline Wikipedia page name for this span would be\n",
    "\n",
    "    Jimi_Hendrix\n",
    "\n",
    "Implement this naive baseline and evaluate its performance. Print the evaluation measures that you implemented in Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here and in the remainder of this lab, you should base your entity predictions on the predicted spans that you computed in Problem&nbsp;3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.32011030971574034\n",
      "Recall:  0.25502788575291535\n",
      "F1 score:  0.2838867463079673\n"
     ]
    }
   ],
   "source": [
    "pred = set()\n",
    "for row in df_dev_pred.itertuples(False):\n",
    "    wiki = '_'.join(row[1].split(' ')[row[2]:row[3]])\n",
    "\n",
    "    pred.add((row[0], row[2], row[3], wiki))\n",
    "    \n",
    "evaluation_report(set(gold_mentions(df_dev)), pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Extending the training data using the knowledge base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State-of-the-art approaches to entity linking exploit information in knowledge bases. In our case, where Wikipedia is the knowledge base, one particularly useful type of information are links to other Wikipedia pages. In particular, we can interpret the anchor texts (the highlighted texts that you click on) as mentions of the entities (pages) that they link to. This allows us to harvest long lists of mention–entity pairings.\n",
    "\n",
    "The following cell loads a data frame summarizing anchor texts and page references harvested from the first paragraphs of the English Wikipedia. The data frame also contains all entity mentions in the training data (but not the development or the test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open('kb.tsv.bz2', 'rt') as source:\n",
    "    df_kb = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what information is available in this data, the following cell shows the entry for the anchor text `Sweden`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>entity</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17436</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>0.985768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden_national_football_team</td>\n",
       "      <td>0.014173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17438</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Sweden_men's_national_ice_hockey_team</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mention                                 entity      prob\n",
       "17436  Sweden                                 Sweden  0.985768\n",
       "17437  Sweden          Sweden_national_football_team  0.014173\n",
       "17438  Sweden  Sweden_men's_national_ice_hockey_team  0.000059"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kb.loc[df_kb.mention == 'Sweden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each row of the data frame contains a pair $(m, e)$ of a mention $m$ and an entity $e$, as well as the conditional probability $P(e|m)$ for mention $m$ referring to entity $e$. These probabilities were estimated based on the frequencies of mention–entity pairs in the knowledge base. The example shows that the anchor text &lsquo;Sweden&rsquo; is most often used to refer to the entity [Sweden](http://en.wikipedia.org/wiki/Sweden), but in a few cases also to refer to Sweden&rsquo;s national football and ice hockey teams. Note that references are sorted in decreasing order of probability, so that the most probable pairing come first.\n",
    "\n",
    "Implement an entity linking method that resolves each mention to the most probable entity in the data frame. If the mention is not included in the data frame, you can predict the generic label `--NME--`. Print the precision, recall, and F1 of your method using the function that you implemented for Problem&nbsp;1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.65634280865507\n",
      "Recall:  0.5229001183031942\n",
      "F1 score:  0.5820713009124259\n"
     ]
    }
   ],
   "source": [
    "pred = set()\n",
    "for row in df_dev_pred.itertuples(False):\n",
    "    mention = ' '.join(row[1].split(' ')[row[2]:row[3]])\n",
    "    mentions = df_kb.loc[df_kb.mention == mention]\n",
    "    if not mentions.empty:\n",
    "        wiki =  mentions.iloc[0][\"entity\"]\n",
    "    else:\n",
    "        wiki = \"--NME--\"\n",
    "        \n",
    "    pred.add((row[0], row[2], row[3], wiki))\n",
    "    \n",
    "evaluation_report(set(gold_mentions(df_dev)), pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Context-sensitive disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the entity mention &lsquo;Lincoln&rsquo;. The most probable entity for this mention turns out to be [Lincoln, Nebraska](http://en.wikipedia.org/Lincoln,_Nebraska); but in pages about American history, we would be better off to predict [Abraham Lincoln](http://en.wikipedia.org/Abraham_Lincoln). This suggests that we should try to disambiguate between different entity references based on the textual context on the page from which the mention was taken. Your task in this last problem is to implement this idea.\n",
    "\n",
    "Set up a dictionary that contains, for each mention $m$ that can refer to more than one entity $e$, a separate Naive Bayes classifier that is trained to predict the correct entity $e$, given the textual context of the mention. As the prior probabilities of the classifier, choose the probabilities $P(e|m)$ that you used in Problem&nbsp;5. To let you estimate the context-specific probabilities, we have compiled a data set with mention contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with bz2.open('contexts.tsv.bz2') as source:\n",
    "    df_contexts = pd.read_csv(source, sep='\\t', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data frame contains, for each ambiguous mention $m$ and each knowledge base entity $e$ to which this mention can refer, up to 100 randomly selected contexts in which $m$ is used to refer to $e$. For this data, a **context** is defined as the 5 tokens to the left and the 5 tokens to the right of the mention. Here are a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mention</th>\n",
       "      <th>entity</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970</td>\n",
       "      <td>UEFA_Champions_League</td>\n",
       "      <td>Cup twice the first in @ and the second in 1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970</td>\n",
       "      <td>FIFA_World_Cup</td>\n",
       "      <td>America 1975 and during the @ and 1978 World C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990 World Cup</td>\n",
       "      <td>1990_FIFA_World_Cup</td>\n",
       "      <td>Manolo represented Spain at the @</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990 World Cup</td>\n",
       "      <td>1990_FIFA_World_Cup</td>\n",
       "      <td>Hašek represented Czechoslovakia at the @ and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990 World Cup</td>\n",
       "      <td>1990_FIFA_World_Cup</td>\n",
       "      <td>renovations in 1989 for the @ The present capa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mention                 entity  \\\n",
       "0            1970  UEFA_Champions_League   \n",
       "1            1970         FIFA_World_Cup   \n",
       "2  1990 World Cup    1990_FIFA_World_Cup   \n",
       "3  1990 World Cup    1990_FIFA_World_Cup   \n",
       "4  1990 World Cup    1990_FIFA_World_Cup   \n",
       "\n",
       "                                             context  \n",
       "0    Cup twice the first in @ and the second in 1983  \n",
       "1  America 1975 and during the @ and 1978 World C...  \n",
       "2                 Manolo represented Spain at the @   \n",
       "3  Hašek represented Czechoslovakia at the @ and ...  \n",
       "4  renovations in 1989 for the @ The present capa...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, in each context, the position of the mention is indicated by the `@` symbol.\n",
    "\n",
    "From this data frame, it is easy to select the data that you need to train the classifiers – the contexts and corresponding entities for all mentions. To illustrate this, the following cell shows how to select all contexts that belong to the mention &lsquo;Lincoln&rsquo;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41465    Nebraska Concealed Handgun Permit In @ municip...\n",
       "41466    Lazlo restaurants are located in @ and Omaha C...\n",
       "41467    California Washington Overland Park Kansas @ N...\n",
       "41468    City Missouri Omaha Nebraska and @ Nebraska It...\n",
       "41469    by Sandhills Publishing Company in @ Nebraska USA\n",
       "                               ...                        \n",
       "41609                                      @ Leyton Orient\n",
       "41610                    English division three Swansea @ \n",
       "41611    league membership narrowly edging out @ on goa...\n",
       "41612                                          @ Cambridge\n",
       "41613                                                   @ \n",
       "Name: context, Length: 149, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contexts.context[df_contexts.mention == 'Lincoln']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the context-sensitive disambiguation method and evaluate its performance. Here are some more hints that may help you along the way:\n",
    "\n",
    "**Hint 1:** The prior probabilities for a Naive Bayes classifier can be specified using the `class_prior` option. You will have to provide the probabilities in the same order as the alphabetically sorted class (entity) names.\n",
    "\n",
    "**Hint 2:** Not all mentions in the knowledge base are ambiguous, and therefore not all mentions have context data. If a mention has only one possible entity, pick that one. If a mention has no entity at all, predict the `--NME--` label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "dic = {}\n",
    "\n",
    "class dummyCount():\n",
    "    \n",
    "    def transform(self, junk):\n",
    "        return junk\n",
    "\n",
    "class dummyPredict():\n",
    "    \n",
    "    def __init__(self, entry):\n",
    "        self.entry = entry\n",
    "        \n",
    "    def predict(self, junk):\n",
    "        return self.entry\n",
    "    \n",
    "for mention in df_kb.mention.unique():\n",
    "    entities = df_kb.loc[df_kb.mention == mention].sort_values(by=[\"entity\"])\n",
    "    if len(entities) > 1:\n",
    "        clf = MultinomialNB(class_prior=entities[\"prob\"].to_numpy())\n",
    "        X = df_contexts.context[df_contexts.mention == mention].to_numpy()\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(X)\n",
    "        Y = df_contexts.entity[df_contexts.mention == mention].to_numpy()\n",
    "        clf.fit(X, Y)\n",
    "        dic[mention] = (clf, vectorizer)\n",
    "    else:\n",
    "        dic[mention] = (dummyPredict(entities[\"entity\"].values), dummyCount())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.671828595672465\n",
      "Recall:  0.5352374514111881\n",
      "F1 score:  0.5958047220393189\n"
     ]
    }
   ],
   "source": [
    "pred = set()\n",
    "for row in df_dev_pred.itertuples(False):\n",
    "    mention = ' '.join(row[1].split(' ')[row[2]:row[3]])\n",
    "    if mention in dic:\n",
    "        mentions = dic[mention]\n",
    "        X = mentions[1].transform([row[1]])\n",
    "        wiki =  mentions[0].predict(X)[0]\n",
    "    else:\n",
    "        wiki = \"--NME--\"\n",
    "        \n",
    "    pred.add((row[0], row[2], row[3], wiki))\n",
    "    \n",
    "evaluation_report(set(gold_mentions(df_dev)), pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect to see a small (around 1&nbsp;unit) increase in both precision, recall, and F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following reflection questions will help you prepare for the diagnostic test. Answer each of them in the form of a short text and put your answers in the cell below. You will get feedback on your answers from your lab assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RQ 5.1:** In Problem&nbsp;3, you did an error analysis on the task of recognizing text spans mentioning named entities. Summarize your results. Pick one type of error that you observed. How could you improve the model&rsquo;s performance on this type of error? What resources (such as domain knowledge, data, compute) would you need to implement this improvement?\n",
    "\n",
    "**RQ 5.2:** Thinking back about Problem&nbsp;6, explain what the word *context* refers to in the task addressed there, and how context can help to disambiguate between different entities. Suggest other types of context that you could use for disambiguation.\n",
    "\n",
    "**RQ 5.3:** One type of entity mentions that we did not cover explicitly in this lab are pronouns. As an example, consider the sentence pair *Ruth Bader Ginsburg was an American jurist*. *She served as an associate justice of the Supreme Court from 1993 until her death in 2020*. What facts would you want to extract from this sentence pair? How do pronouns make fact extraction hard?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1**: One of the most common errors we observed was that the model kept missing the names of non-american people and locations. This could be solved by giving the model more data from different nations.\n",
    "\n",
    "**5.2**: Context in this case refers to the sentence the given word was a part of. When words about sports occur around the given world, like for example sweden, then we can assume that the lable is not the county but the sports team. Another type of context we could use would be to the sentences by having an unsupervised model identify the topics of the sentence, then the topics could be used to figure out what the word could be referring to.\n",
    "\n",
    "**5.3**: The facts we would like to extract from this pair would be that Ruth served in the Supreme Court. The problem in this case is that the only link between these sentences is the pronoun \"she\". For a program to be able to connect these two sentences with the help of the pronoun would require abilites to recognize context over multiple sentences and not just locally like how it was performed in problem 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This was the last lab in the Text Mining course. Congratulations! 🥳**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
